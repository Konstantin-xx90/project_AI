{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74870c21-cee1-4b0e-b00c-62a3e970972e",
   "metadata": {},
   "source": [
    "# Project: Artificial Intelligence - Python Project\n",
    "\n",
    "### 1. Initialization and Data Paths\n",
    "#### 1.1 Import Libraries and Define Paths\n",
    "#### 1.2 Define Paths to the Datasets\n",
    "#### 1.3 Define Global Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6159be3-34a3-4d13-9be5-9da1743f0179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Import necessary deep learning and plotting libraries\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping,  ModelCheckpoint\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "\n",
    "# Set up of further Markdown possibilities (only required for JupyterLab)\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "# 1.2 Define the paths to the datasets\n",
    "# NOTE: Please ensure these paths are correct on your system!\n",
    "train_dir = \"/Users/konstantinhanemann/PycharmProjects/Project_AI/archive/train\"\n",
    "test_dir = \"/Users/konstantinhanemann/PycharmProjects/Project_AI/archive/test\"\n",
    "\n",
    "# 1.3 Define global training parameters\n",
    "img_size = (48, 48)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7fd848-64d5-4d03-bf87-64fffdc50d63",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing and Generators\n",
    "#### 2.1 Create Data Augmentatiion and Generators\n",
    "#### 2.2 Separate the Dataset\n",
    "#### 2.3 Display the class indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a8ef6-ada3-4006-9df6-aee74df1a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd(\"**Display of the Class indices**\")\n",
    "# Training Generator: Scaling and reserving 20% for validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    validation_split=0.2,\n",
    "\n",
    "    rotation_range=10,        # Small Rotation\n",
    "    width_shift_range=0.0,   # Horizontal Switch\n",
    "    height_shift_range=0.0,  # Vertical Switch\n",
    "    shear_range=0.0,          # Shear\n",
    "    zoom_range=0.0,          # Zoom\n",
    "    horizontal_flip=True,     # Horizontal Mirroring\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Test Generator: Scaling only (no augmentation for test data!)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Training Set Generator: Loads images and maps them to classes\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\", # Grayscale images\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "# Validation Set Generator\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "# Test Set Generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "\n",
    "aggressive_class_weights = {\n",
    "    0: 2.0,  # Angry: High weight\n",
    "    1: 2.5,  # Fear: Highest weight due to critical failure (0.05 Recall)\n",
    "    2: 1.0,  # Happy: Moderate weight\n",
    "    3: 0.8   # None: Ultra-low weight (was 0.5 in earlier suggestions)\n",
    "}\n",
    "\n",
    "# Calculate class weights to equalize the weights\n",
    "true_labels = train_generator.classes\n",
    "unique_classes = np.unique(true_labels)\n",
    "\n",
    "# Calculate the weights\n",
    "weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=unique_classes,\n",
    "    y=true_labels\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(weights))\n",
    "class_counts = np.bincount(true_labels)\n",
    "\n",
    "printmd(\"<br>**Calculated Class-weights**\")\n",
    "print(\"Examples of each class:\", class_counts) \n",
    "print(\"Class-Weights (Index: Weight):\", class_weights)\n",
    "\n",
    "# Display the class indices (mapping from name to number)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "printmd(\"<br>**Class Information**\")\n",
    "print(\"Number of Classes:\", num_classes)\n",
    "print(\"Class Mapping:\", train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e92e7d-a1db-4f2e-a374-dd3ab7119096",
   "metadata": {},
   "source": [
    "### 3. Define the CNN Model Architecture\n",
    "#### 3.1 Create the Model Architecture\n",
    "#### 3.2 Compile the Model\n",
    "#### 3.3 Display the summary of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b1273-03fc-4503-b5ee-b8fa86c75766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dynamic number of classes\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# Create the sequential model architecture\n",
    "model = Sequential([\n",
    "    # First Conv Block: 32 Filters\n",
    "    Conv2D(32, (3, 3), activation=\"relu\", input_shape=(48, 48, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Second Conv Block: 64 Filters\n",
    "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.6), # Dropout for regularization\n",
    "\n",
    "    # Third Conv Block: 128 Filters\n",
    "    Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.6),\n",
    "\n",
    "    # Classification Part\n",
    "    Flatten(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dropout(0.7),\n",
    "    Dense(num_classes, activation=\"softmax\") # Output Layer: Softmax for classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001), # Explicit Adam optimizer\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display a summary of the model\n",
    "printmd(\"**Summary of the CNN Architecture**\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2d10a2-3ee7-4b67-b148-0fd5be8c2339",
   "metadata": {},
   "source": [
    "### 4. Model Training\n",
    "#### 4.1 Perform Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e045a44a-3cd0-4d10-b784-dd3e76b032bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training process\n",
    "\n",
    "# Define the Early Stopping Callback\n",
    "# monitor='val_loss': Monitor the validation loss (should be minimized)\n",
    "# patience=10: Wait 10 epochs with no improvement before stopping training\n",
    "# restore_best_weights=True: Restores the weights from the epoch with the best 'val_loss'\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=30, \n",
    "    verbose=1, \n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Define the Model Checkpoint Callback for saving the best model\n",
    "# monitor='val_accuracy': Monitor the validation accuracy (should be maximized)\n",
    "# save_best_only=True: Only saves the model if the metric is better than before\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='best_emotion_model_checkpoint.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create the list of callbacks\n",
    "callbacks_list = [early_stopping, model_checkpoint]\n",
    "\n",
    "print(f\"\\nStarting training over epochs...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=150,\n",
    "    callbacks=callbacks_list,\n",
    "\n",
    "    class_weight=aggressive_class_weights\n",
    ")\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57547cb-6a3c-4e48-93ff-ab722941832f",
   "metadata": {},
   "source": [
    "### 5. Evaluation and Improvement\n",
    "#### 5.1 Evaluate Model on Test Data\n",
    "#### 5.2 Visualize Training History\n",
    "#### 5.3 Further Statistical Insights\n",
    "#### 5.4 Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7118dc-17c5-4661-b370-d75459316585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "printmd(\"**Model Evaluation**\")\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465628b6-e772-4381-93fe-953c3376617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of accuracy during training\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\", color='blue')\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\", color='orange')\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Note on interpretation: A large gap between the lines suggests overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a59c5d8-8cf1-44ec-9513-884826c808e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EMOTION_CLASSES = [\"Angry\", \"Fear\", \"Happy\", \"None\"] \n",
    "\n",
    "# 1. Get Predictions on the validation dataset\n",
    "validation_steps = val_generator.n // val_generator.batch_size + 1 \n",
    "\n",
    "# Raw predictions (Probabilities)\n",
    "Y_pred = model.predict(val_generator, steps=validation_steps)\n",
    "# Convert probabilities to class labels (index of the highest probability)\n",
    "y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "# Retrieve the true labels of the validation dataset\n",
    "y_true = val_generator.classes\n",
    "\n",
    "# 2. Create the Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "# 3. Visualize the Confusion Matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Use EMOTION_CLASSES from your script here\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=EMOTION_CLASSES, yticklabels=EMOTION_CLASSES)\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('True Class')\n",
    "plt.title('Confusion Matrix for Emotion Recognition')\n",
    "plt.show()\n",
    "\n",
    "# 4. Output the detailed classification report (next section)\n",
    "print(classification_report(y_true, y_pred_classes, target_names=EMOTION_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b309f8f9-7bb7-46d5-a4bf-628e007ba40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model in Keras format\n",
    "final_model = load_model(\"best_emotion_model_checkpoint.keras\")\n",
    "final_model.save(\"final_stable_emotion_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow M2 (GPU)",
   "language": "python",
   "name": "tf_m2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "panel-cell-order": [
   "79334a9b-1da6-4fd7-9374-369e6da12f97"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
