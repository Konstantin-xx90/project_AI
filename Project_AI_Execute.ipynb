{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2b9fefd-4e09-4e7c-b7ad-171238e2fdcc",
   "metadata": {},
   "source": [
    "# Project: Artificial Intelligence - Python Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e3913-a683-4d8c-846f-a0f2d57fd01f",
   "metadata": {},
   "source": [
    "### 1. Set Up the Model\n",
    "### 1.1 Initialization and Imports\n",
    "### 1.2 Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f35eeb-f373-4c06-a3b2-340313b83768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# ----------------- CONSTANTS -----------------\n",
    "\n",
    "# Specify the path to your best trained model\n",
    "# IMPORTANT: Use the final stable model name!\n",
    "MODEL_PATH = \"final_stable_emotion_model.keras\" \n",
    "\n",
    "# Define the expected input image size (must match the model's training)\n",
    "IMG_SIZE = (48, 48)\n",
    "\n",
    "# Define the emotion classes (order must match the model's output order)\n",
    "EMOTION_CLASSES = [\"Angry\", \"Fear\", \"Happy\", \"None\"]\n",
    "\n",
    "# ----------------- LOAD MODEL -----------------\n",
    "\n",
    "try:\n",
    "    # Load the trained model from disk\n",
    "    model = load_model(MODEL_PATH)\n",
    "    print(f\"Model successfully loaded from: {MODEL_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR loading the model: {e}\")\n",
    "    print(\"Please ensure the file 'final_stable_emotion_model.keras' exists in this directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ab14e-7053-45d6-b3da-e596c7340934",
   "metadata": {},
   "source": [
    "### 2. Define the Function for Emotion Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39376b52-57ab-4afc-974f-fc1f206e6dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(image_path):\n",
    "    \"\"\"\n",
    "    Predicts the emotion from a grayscale face image.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (str: Predicted Label, np.ndarray: Prediction probabilities)\n",
    "    \"\"\"\n",
    "    # Load the input image in grayscale mode\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Image not found at path: {image_path}\")\n",
    "\n",
    "    # 1. Image Preprocessing\n",
    "    img = cv2.resize(img, IMG_SIZE)\n",
    "    img = img.astype('float32') / 255.0  # Normalization\n",
    "    # Reshape: (1, 48, 48, 1) - Batch size 1, Height, Width, 1 Channel (Grayscale)\n",
    "    img = img.reshape(1, IMG_SIZE[0], IMG_SIZE[1], 1)\n",
    "\n",
    "    # 2. Prediction\n",
    "    # verbose=0 suppresses the Keras output like '1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step'\n",
    "    prediction = model.predict(img, verbose=0)[0] \n",
    "    emotion_index = np.argmax(prediction)\n",
    "\n",
    "    # 3. Result\n",
    "    detected_emotion = EMOTION_CLASSES[emotion_index]\n",
    "\n",
    "    return detected_emotion, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf26821d-867d-446c-ae68-00a4d8887f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_prediction(image_path, detected_emotion, probabilities):\n",
    "    \"\"\"\n",
    "    Displays the image along with the predicted label and probabilities.\n",
    "    \"\"\"\n",
    "    # Re-load the image to display in color (or its original format)\n",
    "    img_display = cv2.imread(image_path)\n",
    "    \n",
    "    if img_display is None:\n",
    "        print(f\"Visualization image not found: {image_path}\")\n",
    "        return\n",
    "\n",
    "    # OpenCV reads as BGR, Matplotlib expects RGB\n",
    "    img_display = cv2.cvtColor(img_display, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Formatting the probabilities for display\n",
    "    prob_text = [f\"{EMOTION_CLASSES[i]}: {p*100:.1f}%\" for i, p in enumerate(probabilities)]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(img_display)\n",
    "    \n",
    "    # Title with the result and all probabilities\n",
    "    title = f\"Predicted Emotion: {detected_emotion}\\n\"\n",
    "    title += \"\\n\".join(prob_text)\n",
    "    \n",
    "    plt.title(title, fontsize=12)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# ----------------- TEST EXECUTION -----------------\n",
    "\n",
    "# NOTE: REPLACE THIS WITH THE PATH TO YOUR TEST IMAGE!\n",
    "TEST_IMAGE_PATH = \"/Users/konstantinhanemann/PycharmProjects/Project_AI/test_image.jpg\"\n",
    "\n",
    "try:\n",
    "    predicted_label, probs = predict_emotion(TEST_IMAGE_PATH)\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Result for '{TEST_IMAGE_PATH}':\")\n",
    "    print(f\"-> Detected Emotion: {predicted_label}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    display_prediction(TEST_IMAGE_PATH, predicted_label, probs)\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd012f3-b4ba-429d-a893-f9975155e1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow M2 (GPU)",
   "language": "python",
   "name": "tf_m2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
